{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+Vi4ty7caJQcTw24f/6OJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sc7-cloud/TFG---GOOGLE-COLAB-C-DIGOS-/blob/main/MODELOS_DE_PREDICCI%C3%93N.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd_P3IOUdMZ8",
        "outputId": "b8d9a53e-e17a-4b96-80ab-b2c3ead49f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Seguidores en Spotify  log_Seguidores_Spotify  \\\n",
            "0                 704502               13.465248   \n",
            "1               13020064               16.382002   \n",
            "2                5355925               15.493714   \n",
            "3               12859303               16.369578   \n",
            "4                4321836               15.279191   \n",
            "\n",
            "   Oyentes mensuales en Spotify  log_Oyentes_mensuales_Spotify  \n",
            "0                      42896849                      17.574309  \n",
            "1                      52843480                      17.782845  \n",
            "2                      31490006                      17.265181  \n",
            "3                      41343279                      17.537420  \n",
            "4                      29445103                      17.198038  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_excel('/content/Artistas.xlsx')\n",
        "\n",
        "\n",
        "\n",
        "data['log_Seguidores_Spotify'] = np.log(data['Seguidores en Spotify'] + 1)\n",
        "data['log_Oyentes_mensuales_Spotify'] = np.log(data['Oyentes mensuales en Spotify'] + 1)\n",
        "\n",
        "\n",
        "data.to_excel('nuevo_archivo_transformado.xlsx', index=False)\n",
        "\n",
        "\n",
        "print(data[['Seguidores en Spotify', 'log_Seguidores_Spotify', 'Oyentes mensuales en Spotify', 'log_Oyentes_mensuales_Spotify']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_excel('/content/nuevo_archivo_transformado.xlsx')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X = data[['log_Seguidores_Spotify', 'log_Oyentes_mensuales_Spotify', 'Tasa de conversión en Spotify', 'Me gusta en TikTok', 'Vistas en TikTok']]\n",
        "y = data['Oyentes mensuales en Spotify']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gb_model.fit(X_train_scaled, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "print(\"Random Forest:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
        "\n",
        "print(\"\\nGradient Boosting:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_gb))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_gb))\n",
        "\n",
        "print(\"\\nLogistic Regression:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1QE24AEepgn",
        "outputId": "0e213d3a-6fa8-48c8-853a-c077b208dc5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest:\n",
            "Accuracy: 0.0\n",
            "Confusion Matrix:\n",
            " [[0 1 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     1046315       0.00      0.00      0.00       1.0\n",
            "     1072000       0.00      0.00      0.00       0.0\n",
            "     1137212       0.00      0.00      0.00       1.0\n",
            "     1190821       0.00      0.00      0.00       1.0\n",
            "     1236353       0.00      0.00      0.00       1.0\n",
            "     1302132       0.00      0.00      0.00       1.0\n",
            "     1470805       0.00      0.00      0.00       1.0\n",
            "     1479110       0.00      0.00      0.00       0.0\n",
            "     1534952       0.00      0.00      0.00       1.0\n",
            "     1539037       0.00      0.00      0.00       0.0\n",
            "     1549684       0.00      0.00      0.00       0.0\n",
            "     1809115       0.00      0.00      0.00       0.0\n",
            "     1859223       0.00      0.00      0.00       1.0\n",
            "     1939744       0.00      0.00      0.00       0.0\n",
            "     1941117       0.00      0.00      0.00       1.0\n",
            "     2080913       0.00      0.00      0.00       0.0\n",
            "     2178515       0.00      0.00      0.00       1.0\n",
            "     2344239       0.00      0.00      0.00       1.0\n",
            "     2411982       0.00      0.00      0.00       1.0\n",
            "     2420364       0.00      0.00      0.00       0.0\n",
            "     2456188       0.00      0.00      0.00       0.0\n",
            "     2465166       0.00      0.00      0.00       1.0\n",
            "     2479947       0.00      0.00      0.00       1.0\n",
            "     2587749       0.00      0.00      0.00       0.0\n",
            "     2590332       0.00      0.00      0.00       1.0\n",
            "     2695730       0.00      0.00      0.00       0.0\n",
            "     2918014       0.00      0.00      0.00       1.0\n",
            "     2936504       0.00      0.00      0.00       0.0\n",
            "     2989255       0.00      0.00      0.00       0.0\n",
            "     3047627       0.00      0.00      0.00       1.0\n",
            "     3252719       0.00      0.00      0.00       1.0\n",
            "     3281169       0.00      0.00      0.00       1.0\n",
            "     3410644       0.00      0.00      0.00       0.0\n",
            "     3468336       0.00      0.00      0.00       0.0\n",
            "     3580539       0.00      0.00      0.00       0.0\n",
            "     3636739       0.00      0.00      0.00       1.0\n",
            "     3797433       0.00      0.00      0.00       1.0\n",
            "     3887189       0.00      0.00      0.00       1.0\n",
            "     3907253       0.00      0.00      0.00       0.0\n",
            "     3959209       0.00      0.00      0.00       0.0\n",
            "     3995954       0.00      0.00      0.00       1.0\n",
            "     4019804       0.00      0.00      0.00       0.0\n",
            "     4629487       0.00      0.00      0.00       1.0\n",
            "     4674913       0.00      0.00      0.00       1.0\n",
            "     4763162       0.00      0.00      0.00       1.0\n",
            "     4786359       0.00      0.00      0.00       0.0\n",
            "     4828187       0.00      0.00      0.00       0.0\n",
            "     4999274       0.00      0.00      0.00       0.0\n",
            "     5021237       0.00      0.00      0.00       0.0\n",
            "     5117820       0.00      0.00      0.00       0.0\n",
            "     5470685       0.00      0.00      0.00       0.0\n",
            "     5607627       0.00      0.00      0.00       1.0\n",
            "     5674393       0.00      0.00      0.00       0.0\n",
            "     5804080       0.00      0.00      0.00       1.0\n",
            "     5810012       0.00      0.00      0.00       0.0\n",
            "     5994615       0.00      0.00      0.00       1.0\n",
            "     6062751       0.00      0.00      0.00       1.0\n",
            "     6189844       0.00      0.00      0.00       0.0\n",
            "     6235980       0.00      0.00      0.00       1.0\n",
            "     6342448       0.00      0.00      0.00       0.0\n",
            "     6381094       0.00      0.00      0.00       1.0\n",
            "     6520404       0.00      0.00      0.00       0.0\n",
            "     6565348       0.00      0.00      0.00       0.0\n",
            "     6808054       0.00      0.00      0.00       1.0\n",
            "     6822868       0.00      0.00      0.00       1.0\n",
            "     7364239       0.00      0.00      0.00       1.0\n",
            "     7393644       0.00      0.00      0.00       1.0\n",
            "     7688158       0.00      0.00      0.00       1.0\n",
            "     7716563       0.00      0.00      0.00       1.0\n",
            "     7873359       0.00      0.00      0.00       1.0\n",
            "     7886648       0.00      0.00      0.00       1.0\n",
            "     7893964       0.00      0.00      0.00       1.0\n",
            "     7943954       0.00      0.00      0.00       0.0\n",
            "     8357525       0.00      0.00      0.00       0.0\n",
            "     8421736       0.00      0.00      0.00       0.0\n",
            "     8479799       0.00      0.00      0.00       0.0\n",
            "     8586027       0.00      0.00      0.00       0.0\n",
            "     8783596       0.00      0.00      0.00       0.0\n",
            "     8907951       0.00      0.00      0.00       1.0\n",
            "     8989970       0.00      0.00      0.00       0.0\n",
            "     9271749       0.00      0.00      0.00       0.0\n",
            "     9505135       0.00      0.00      0.00       1.0\n",
            "     9711537       0.00      0.00      0.00       0.0\n",
            "     9749741       0.00      0.00      0.00       1.0\n",
            "     9783218       0.00      0.00      0.00       1.0\n",
            "     9813058       0.00      0.00      0.00       1.0\n",
            "    10285376       0.00      0.00      0.00       0.0\n",
            "    10619862       0.00      0.00      0.00       0.0\n",
            "    10695720       0.00      0.00      0.00       0.0\n",
            "    10941584       0.00      0.00      0.00       0.0\n",
            "    11149433       0.00      0.00      0.00       1.0\n",
            "    11486450       0.00      0.00      0.00       1.0\n",
            "    11573648       0.00      0.00      0.00       1.0\n",
            "    12214799       0.00      0.00      0.00       1.0\n",
            "    12267695       0.00      0.00      0.00       1.0\n",
            "    12281342       0.00      0.00      0.00       0.0\n",
            "    12364986       0.00      0.00      0.00       1.0\n",
            "    12421478       0.00      0.00      0.00       1.0\n",
            "    12429478       0.00      0.00      0.00       1.0\n",
            "    12506216       0.00      0.00      0.00       0.0\n",
            "    12577728       0.00      0.00      0.00       0.0\n",
            "    12612021       0.00      0.00      0.00       0.0\n",
            "    12638549       0.00      0.00      0.00       1.0\n",
            "    12900312       0.00      0.00      0.00       0.0\n",
            "    12996766       0.00      0.00      0.00       0.0\n",
            "    13011677       0.00      0.00      0.00       1.0\n",
            "    13398699       0.00      0.00      0.00       0.0\n",
            "    13751224       0.00      0.00      0.00       1.0\n",
            "    15052006       0.00      0.00      0.00       0.0\n",
            "    15394623       0.00      0.00      0.00       1.0\n",
            "    15553286       0.00      0.00      0.00       0.0\n",
            "    15568105       0.00      0.00      0.00       0.0\n",
            "    15729786       0.00      0.00      0.00       1.0\n",
            "    16364172       0.00      0.00      0.00       1.0\n",
            "    17266809       0.00      0.00      0.00       1.0\n",
            "    17601362       0.00      0.00      0.00       1.0\n",
            "    17741657       0.00      0.00      0.00       1.0\n",
            "    17959092       0.00      0.00      0.00       1.0\n",
            "    18047545       0.00      0.00      0.00       1.0\n",
            "    19616771       0.00      0.00      0.00       1.0\n",
            "    19853566       0.00      0.00      0.00       0.0\n",
            "    20387376       0.00      0.00      0.00       1.0\n",
            "    20412278       0.00      0.00      0.00       0.0\n",
            "    21825594       0.00      0.00      0.00       0.0\n",
            "    22302422       0.00      0.00      0.00       1.0\n",
            "    22342621       0.00      0.00      0.00       1.0\n",
            "    22356482       0.00      0.00      0.00       0.0\n",
            "    23246211       0.00      0.00      0.00       1.0\n",
            "    25276826       0.00      0.00      0.00       1.0\n",
            "    25432711       0.00      0.00      0.00       0.0\n",
            "    25571310       0.00      0.00      0.00       1.0\n",
            "    25616477       0.00      0.00      0.00       0.0\n",
            "    26845141       0.00      0.00      0.00       1.0\n",
            "    27331581       0.00      0.00      0.00       0.0\n",
            "    28015461       0.00      0.00      0.00       0.0\n",
            "    29279334       0.00      0.00      0.00       0.0\n",
            "    29370502       0.00      0.00      0.00       0.0\n",
            "    30969347       0.00      0.00      0.00       1.0\n",
            "    31453661       0.00      0.00      0.00       0.0\n",
            "    34205812       0.00      0.00      0.00       1.0\n",
            "    34319306       0.00      0.00      0.00       1.0\n",
            "    36551045       0.00      0.00      0.00       1.0\n",
            "    37765438       0.00      0.00      0.00       0.0\n",
            "    38537824       0.00      0.00      0.00       0.0\n",
            "    41343279       0.00      0.00      0.00       1.0\n",
            "    42485870       0.00      0.00      0.00       1.0\n",
            "    42896849       0.00      0.00      0.00       1.0\n",
            "    48274557       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00      81.0\n",
            "   macro avg       0.00      0.00      0.00      81.0\n",
            "weighted avg       0.00      0.00      0.00      81.0\n",
            "\n",
            "\n",
            "Gradient Boosting:\n",
            "Accuracy: 0.0\n",
            "Confusion Matrix:\n",
            " [[0 1 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     1046315       0.00      0.00      0.00       1.0\n",
            "     1072000       0.00      0.00      0.00       0.0\n",
            "     1137212       0.00      0.00      0.00       1.0\n",
            "     1190821       0.00      0.00      0.00       1.0\n",
            "     1236353       0.00      0.00      0.00       1.0\n",
            "     1302132       0.00      0.00      0.00       1.0\n",
            "     1470805       0.00      0.00      0.00       1.0\n",
            "     1479110       0.00      0.00      0.00       0.0\n",
            "     1533563       0.00      0.00      0.00       0.0\n",
            "     1534952       0.00      0.00      0.00       1.0\n",
            "     1859223       0.00      0.00      0.00       1.0\n",
            "     1941117       0.00      0.00      0.00       1.0\n",
            "     2080913       0.00      0.00      0.00       0.0\n",
            "     2090634       0.00      0.00      0.00       0.0\n",
            "     2107600       0.00      0.00      0.00       0.0\n",
            "     2178515       0.00      0.00      0.00       1.0\n",
            "     2192250       0.00      0.00      0.00       0.0\n",
            "     2344239       0.00      0.00      0.00       1.0\n",
            "     2411982       0.00      0.00      0.00       1.0\n",
            "     2420364       0.00      0.00      0.00       0.0\n",
            "     2465166       0.00      0.00      0.00       1.0\n",
            "     2465298       0.00      0.00      0.00       0.0\n",
            "     2479947       0.00      0.00      0.00       1.0\n",
            "     2590332       0.00      0.00      0.00       1.0\n",
            "     2752094       0.00      0.00      0.00       0.0\n",
            "     2807734       0.00      0.00      0.00       0.0\n",
            "     2918014       0.00      0.00      0.00       1.0\n",
            "     3047627       0.00      0.00      0.00       1.0\n",
            "     3252719       0.00      0.00      0.00       1.0\n",
            "     3253838       0.00      0.00      0.00       0.0\n",
            "     3281169       0.00      0.00      0.00       1.0\n",
            "     3443057       0.00      0.00      0.00       0.0\n",
            "     3636739       0.00      0.00      0.00       1.0\n",
            "     3797433       0.00      0.00      0.00       1.0\n",
            "     3887189       0.00      0.00      0.00       1.0\n",
            "     3907253       0.00      0.00      0.00       0.0\n",
            "     3914817       0.00      0.00      0.00       0.0\n",
            "     3959209       0.00      0.00      0.00       0.0\n",
            "     3995954       0.00      0.00      0.00       1.0\n",
            "     4019804       0.00      0.00      0.00       0.0\n",
            "     4231887       0.00      0.00      0.00       0.0\n",
            "     4614392       0.00      0.00      0.00       0.0\n",
            "     4629487       0.00      0.00      0.00       1.0\n",
            "     4674913       0.00      0.00      0.00       1.0\n",
            "     4763162       0.00      0.00      0.00       1.0\n",
            "     4828187       0.00      0.00      0.00       0.0\n",
            "     4935242       0.00      0.00      0.00       0.0\n",
            "     4952897       0.00      0.00      0.00       0.0\n",
            "     5020995       0.00      0.00      0.00       0.0\n",
            "     5021237       0.00      0.00      0.00       0.0\n",
            "     5095133       0.00      0.00      0.00       0.0\n",
            "     5097755       0.00      0.00      0.00       0.0\n",
            "     5248107       0.00      0.00      0.00       0.0\n",
            "     5607627       0.00      0.00      0.00       1.0\n",
            "     5804080       0.00      0.00      0.00       1.0\n",
            "     5949396       0.00      0.00      0.00       0.0\n",
            "     5994615       0.00      0.00      0.00       1.0\n",
            "     6062751       0.00      0.00      0.00       1.0\n",
            "     6235980       0.00      0.00      0.00       1.0\n",
            "     6381094       0.00      0.00      0.00       1.0\n",
            "     6519502       0.00      0.00      0.00       0.0\n",
            "     6808054       0.00      0.00      0.00       1.0\n",
            "     6822868       0.00      0.00      0.00       1.0\n",
            "     6955997       0.00      0.00      0.00       0.0\n",
            "     7305299       0.00      0.00      0.00       0.0\n",
            "     7364239       0.00      0.00      0.00       1.0\n",
            "     7393644       0.00      0.00      0.00       1.0\n",
            "     7529359       0.00      0.00      0.00       0.0\n",
            "     7688158       0.00      0.00      0.00       1.0\n",
            "     7716563       0.00      0.00      0.00       1.0\n",
            "     7829673       0.00      0.00      0.00       0.0\n",
            "     7844461       0.00      0.00      0.00       0.0\n",
            "     7873359       0.00      0.00      0.00       1.0\n",
            "     7886648       0.00      0.00      0.00       1.0\n",
            "     7893964       0.00      0.00      0.00       1.0\n",
            "     8396790       0.00      0.00      0.00       0.0\n",
            "     8421736       0.00      0.00      0.00       0.0\n",
            "     8696537       0.00      0.00      0.00       0.0\n",
            "     8802956       0.00      0.00      0.00       0.0\n",
            "     8907951       0.00      0.00      0.00       1.0\n",
            "     9223603       0.00      0.00      0.00       0.0\n",
            "     9462491       0.00      0.00      0.00       0.0\n",
            "     9505135       0.00      0.00      0.00       1.0\n",
            "     9749741       0.00      0.00      0.00       1.0\n",
            "     9783218       0.00      0.00      0.00       1.0\n",
            "     9813058       0.00      0.00      0.00       1.0\n",
            "     9859900       0.00      0.00      0.00       0.0\n",
            "    10184830       0.00      0.00      0.00       0.0\n",
            "    10285376       0.00      0.00      0.00       0.0\n",
            "    10941584       0.00      0.00      0.00       0.0\n",
            "    11149433       0.00      0.00      0.00       1.0\n",
            "    11486450       0.00      0.00      0.00       1.0\n",
            "    11573648       0.00      0.00      0.00       1.0\n",
            "    11629777       0.00      0.00      0.00       0.0\n",
            "    11721563       0.00      0.00      0.00       0.0\n",
            "    12214799       0.00      0.00      0.00       1.0\n",
            "    12267695       0.00      0.00      0.00       1.0\n",
            "    12364986       0.00      0.00      0.00       1.0\n",
            "    12421478       0.00      0.00      0.00       1.0\n",
            "    12429478       0.00      0.00      0.00       1.0\n",
            "    12638549       0.00      0.00      0.00       1.0\n",
            "    12873481       0.00      0.00      0.00       0.0\n",
            "    12996766       0.00      0.00      0.00       0.0\n",
            "    13011677       0.00      0.00      0.00       1.0\n",
            "    13138866       0.00      0.00      0.00       0.0\n",
            "    13751224       0.00      0.00      0.00       1.0\n",
            "    15394623       0.00      0.00      0.00       1.0\n",
            "    15729786       0.00      0.00      0.00       1.0\n",
            "    16364172       0.00      0.00      0.00       1.0\n",
            "    17266809       0.00      0.00      0.00       1.0\n",
            "    17601362       0.00      0.00      0.00       1.0\n",
            "    17613938       0.00      0.00      0.00       0.0\n",
            "    17741657       0.00      0.00      0.00       1.0\n",
            "    17959092       0.00      0.00      0.00       1.0\n",
            "    18047545       0.00      0.00      0.00       1.0\n",
            "    18238953       0.00      0.00      0.00       0.0\n",
            "    19616771       0.00      0.00      0.00       1.0\n",
            "    20387376       0.00      0.00      0.00       1.0\n",
            "    20412278       0.00      0.00      0.00       0.0\n",
            "    22302422       0.00      0.00      0.00       1.0\n",
            "    22342621       0.00      0.00      0.00       1.0\n",
            "    23012581       0.00      0.00      0.00       0.0\n",
            "    23246211       0.00      0.00      0.00       1.0\n",
            "    25276826       0.00      0.00      0.00       1.0\n",
            "    25571310       0.00      0.00      0.00       1.0\n",
            "    26845141       0.00      0.00      0.00       1.0\n",
            "    29279334       0.00      0.00      0.00       0.0\n",
            "    30969347       0.00      0.00      0.00       1.0\n",
            "    34205812       0.00      0.00      0.00       1.0\n",
            "    34319306       0.00      0.00      0.00       1.0\n",
            "    36551045       0.00      0.00      0.00       1.0\n",
            "    41343279       0.00      0.00      0.00       1.0\n",
            "    42485870       0.00      0.00      0.00       1.0\n",
            "    42896849       0.00      0.00      0.00       1.0\n",
            "    48274557       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00      81.0\n",
            "   macro avg       0.00      0.00      0.00      81.0\n",
            "weighted avg       0.00      0.00      0.00      81.0\n",
            "\n",
            "\n",
            "Logistic Regression:\n",
            "Accuracy: 0.0\n",
            "Confusion Matrix:\n",
            " [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      795611       0.00      0.00      0.00       0.0\n",
            "     1046315       0.00      0.00      0.00       1.0\n",
            "     1072000       0.00      0.00      0.00       0.0\n",
            "     1137212       0.00      0.00      0.00       1.0\n",
            "     1190821       0.00      0.00      0.00       1.0\n",
            "     1236353       0.00      0.00      0.00       1.0\n",
            "     1302132       0.00      0.00      0.00       1.0\n",
            "     1425938       0.00      0.00      0.00       0.0\n",
            "     1470805       0.00      0.00      0.00       1.0\n",
            "     1534952       0.00      0.00      0.00       1.0\n",
            "     1539037       0.00      0.00      0.00       0.0\n",
            "     1549684       0.00      0.00      0.00       0.0\n",
            "     1700046       0.00      0.00      0.00       0.0\n",
            "     1839233       0.00      0.00      0.00       0.0\n",
            "     1859223       0.00      0.00      0.00       1.0\n",
            "     1918876       0.00      0.00      0.00       0.0\n",
            "     1941117       0.00      0.00      0.00       1.0\n",
            "     2005890       0.00      0.00      0.00       0.0\n",
            "     2178515       0.00      0.00      0.00       1.0\n",
            "     2202505       0.00      0.00      0.00       0.0\n",
            "     2344239       0.00      0.00      0.00       1.0\n",
            "     2411982       0.00      0.00      0.00       1.0\n",
            "     2465166       0.00      0.00      0.00       1.0\n",
            "     2479947       0.00      0.00      0.00       1.0\n",
            "     2590332       0.00      0.00      0.00       1.0\n",
            "     2918014       0.00      0.00      0.00       1.0\n",
            "     2989255       0.00      0.00      0.00       0.0\n",
            "     3047627       0.00      0.00      0.00       1.0\n",
            "     3252719       0.00      0.00      0.00       1.0\n",
            "     3281169       0.00      0.00      0.00       1.0\n",
            "     3410644       0.00      0.00      0.00       0.0\n",
            "     3569618       0.00      0.00      0.00       0.0\n",
            "     3636739       0.00      0.00      0.00       1.0\n",
            "     3797433       0.00      0.00      0.00       1.0\n",
            "     3887189       0.00      0.00      0.00       1.0\n",
            "     3913390       0.00      0.00      0.00       0.0\n",
            "     3995954       0.00      0.00      0.00       1.0\n",
            "     4019804       0.00      0.00      0.00       0.0\n",
            "     4231887       0.00      0.00      0.00       0.0\n",
            "     4629487       0.00      0.00      0.00       1.0\n",
            "     4674913       0.00      0.00      0.00       1.0\n",
            "     4763162       0.00      0.00      0.00       1.0\n",
            "     5009625       0.00      0.00      0.00       0.0\n",
            "     5097755       0.00      0.00      0.00       0.0\n",
            "     5596921       0.00      0.00      0.00       0.0\n",
            "     5607627       0.00      0.00      0.00       1.0\n",
            "     5694573       0.00      0.00      0.00       0.0\n",
            "     5804080       0.00      0.00      0.00       1.0\n",
            "     5994615       0.00      0.00      0.00       1.0\n",
            "     6062751       0.00      0.00      0.00       1.0\n",
            "     6235980       0.00      0.00      0.00       1.0\n",
            "     6374825       0.00      0.00      0.00       0.0\n",
            "     6381094       0.00      0.00      0.00       1.0\n",
            "     6808054       0.00      0.00      0.00       1.0\n",
            "     6822868       0.00      0.00      0.00       1.0\n",
            "     7305299       0.00      0.00      0.00       0.0\n",
            "     7364239       0.00      0.00      0.00       1.0\n",
            "     7393644       0.00      0.00      0.00       1.0\n",
            "     7457085       0.00      0.00      0.00       0.0\n",
            "     7688158       0.00      0.00      0.00       1.0\n",
            "     7716563       0.00      0.00      0.00       1.0\n",
            "     7775408       0.00      0.00      0.00       0.0\n",
            "     7837086       0.00      0.00      0.00       0.0\n",
            "     7873359       0.00      0.00      0.00       1.0\n",
            "     7886648       0.00      0.00      0.00       1.0\n",
            "     7893964       0.00      0.00      0.00       1.0\n",
            "     8180649       0.00      0.00      0.00       0.0\n",
            "     8687936       0.00      0.00      0.00       0.0\n",
            "     8783596       0.00      0.00      0.00       0.0\n",
            "     8907951       0.00      0.00      0.00       1.0\n",
            "     9505135       0.00      0.00      0.00       1.0\n",
            "     9749741       0.00      0.00      0.00       1.0\n",
            "     9783218       0.00      0.00      0.00       1.0\n",
            "     9813058       0.00      0.00      0.00       1.0\n",
            "    10217210       0.00      0.00      0.00       0.0\n",
            "    10941584       0.00      0.00      0.00       0.0\n",
            "    11149433       0.00      0.00      0.00       1.0\n",
            "    11335713       0.00      0.00      0.00       0.0\n",
            "    11486450       0.00      0.00      0.00       1.0\n",
            "    11573648       0.00      0.00      0.00       1.0\n",
            "    12214799       0.00      0.00      0.00       1.0\n",
            "    12267695       0.00      0.00      0.00       1.0\n",
            "    12364986       0.00      0.00      0.00       1.0\n",
            "    12421478       0.00      0.00      0.00       1.0\n",
            "    12429478       0.00      0.00      0.00       1.0\n",
            "    12638549       0.00      0.00      0.00       1.0\n",
            "    13011677       0.00      0.00      0.00       1.0\n",
            "    13432396       0.00      0.00      0.00       0.0\n",
            "    13751224       0.00      0.00      0.00       1.0\n",
            "    15394623       0.00      0.00      0.00       1.0\n",
            "    15553286       0.00      0.00      0.00       0.0\n",
            "    15729786       0.00      0.00      0.00       1.0\n",
            "    16364172       0.00      0.00      0.00       1.0\n",
            "    16911217       0.00      0.00      0.00       0.0\n",
            "    17266809       0.00      0.00      0.00       1.0\n",
            "    17601362       0.00      0.00      0.00       1.0\n",
            "    17741657       0.00      0.00      0.00       1.0\n",
            "    17959092       0.00      0.00      0.00       1.0\n",
            "    18047545       0.00      0.00      0.00       1.0\n",
            "    19202593       0.00      0.00      0.00       0.0\n",
            "    19598633       0.00      0.00      0.00       0.0\n",
            "    19616771       0.00      0.00      0.00       1.0\n",
            "    20387376       0.00      0.00      0.00       1.0\n",
            "    20968391       0.00      0.00      0.00       0.0\n",
            "    21475509       0.00      0.00      0.00       0.0\n",
            "    22302422       0.00      0.00      0.00       1.0\n",
            "    22342621       0.00      0.00      0.00       1.0\n",
            "    23246211       0.00      0.00      0.00       1.0\n",
            "    23467103       0.00      0.00      0.00       0.0\n",
            "    25276826       0.00      0.00      0.00       1.0\n",
            "    25571310       0.00      0.00      0.00       1.0\n",
            "    25675507       0.00      0.00      0.00       0.0\n",
            "    26845141       0.00      0.00      0.00       1.0\n",
            "    27596180       0.00      0.00      0.00       0.0\n",
            "    29370502       0.00      0.00      0.00       0.0\n",
            "    29559116       0.00      0.00      0.00       0.0\n",
            "    29728539       0.00      0.00      0.00       0.0\n",
            "    30969347       0.00      0.00      0.00       1.0\n",
            "    33423023       0.00      0.00      0.00       0.0\n",
            "    34205812       0.00      0.00      0.00       1.0\n",
            "    34319306       0.00      0.00      0.00       1.0\n",
            "    34763199       0.00      0.00      0.00       0.0\n",
            "    36551045       0.00      0.00      0.00       1.0\n",
            "    37765438       0.00      0.00      0.00       0.0\n",
            "    38097608       0.00      0.00      0.00       0.0\n",
            "    41343279       0.00      0.00      0.00       1.0\n",
            "    42485870       0.00      0.00      0.00       1.0\n",
            "    42896849       0.00      0.00      0.00       1.0\n",
            "    48274557       0.00      0.00      0.00       1.0\n",
            "    50081113       0.00      0.00      0.00       0.0\n",
            "    52843480       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00      81.0\n",
            "   macro avg       0.00      0.00      0.00      81.0\n",
            "weighted avg       0.00      0.00      0.00      81.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "data = pd.read_excel('nuevo_archivo_transformado.xlsx')\n",
        "\n",
        "\n",
        "X = data[['log_Seguidores_Spotify', 'log_Oyentes_mensuales_Spotify', 'Tasa de conversión en Spotify', 'Me gusta en TikTok', 'Vistas en TikTok']]\n",
        "y = data['Oyentes mensuales en Spotify']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "gb_model.fit(X_train_scaled, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "print(\"Random Forest Regressor:\")\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred_rf))\n",
        "print(\"R2 Score:\", r2_score(y_test, y_pred_rf))\n",
        "\n",
        "print(\"\\nGradient Boosting Regressor:\")\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred_gb))\n",
        "print(\"R2 Score:\", r2_score(y_test, y_pred_gb))\n",
        "\n",
        "print(\"\\nLinear Regression:\")\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred_lr))\n",
        "print(\"R2 Score:\", r2_score(y_test, y_pred_lr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txvMdnEsfaRU",
        "outputId": "71eb4afe-819d-4e45-b4bf-e23cd7b3e28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor:\n",
            "Mean Squared Error: 435217062013.8301\n",
            "R2 Score: 0.9964779381596575\n",
            "\n",
            "Gradient Boosting Regressor:\n",
            "Mean Squared Error: 506657489818.03754\n",
            "R2 Score: 0.9958997953739342\n",
            "\n",
            "Linear Regression:\n",
            "Mean Squared Error: 27338504381691.33\n",
            "R2 Score: 0.7787588965164843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "data = pd.read_excel('nuevo_archivo_transformado.xlsx')\n",
        "\n",
        "\n",
        "data['log_Oyentes_mensuales_Spotify'] = np.log(data['Oyentes mensuales en Spotify'] + 1)\n",
        "\n",
        "\n",
        "X = data[['log_Seguidores_Spotify', 'log_Oyentes_mensuales_Spotify', 'Tasa de conversión en Spotify', 'Me gusta en TikTok', 'Vistas en TikTok']]\n",
        "y = data['log_Oyentes_mensuales_Spotify']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "gb_model.fit(X_train_scaled, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "print(\"Random Forest Regressor:\")\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred_rf))\n",
        "print(\"R2 Score:\", r2_score(y_test, y_pred_rf))\n",
        "\n",
        "print(\"\\nGradient Boosting Regressor:\")\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred_gb))\n",
        "print(\"R2 Score:\", r2_score(y_test, y_pred_gb))\n",
        "\n",
        "print(\"\\nLinear Regression:\")\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred_lr))\n",
        "print(\"R2 Score:\", r2_score(y_test, y_pred_lr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myKI8G6zgG4J",
        "outputId": "2df21958-0d57-4bce-9cf8-fcd6ba97a52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor:\n",
            "Mean Squared Error: 0.0007013177129076775\n",
            "R2 Score: 0.9992867846609401\n",
            "\n",
            "Gradient Boosting Regressor:\n",
            "Mean Squared Error: 0.0007134572873459533\n",
            "R2 Score: 0.9992744391425827\n",
            "\n",
            "Linear Regression:\n",
            "Mean Squared Error: 0.0\n",
            "R2 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf_model = RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_split=10, random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
        "gb_model.fit(X_train_scaled, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test_scaled)\n"
      ],
      "metadata": {
        "id": "DSL2Jj42gqjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "rf_cv_scores = cross_val_score(rf_model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "print(\"Cross-Validation MSE for Random Forest:\", -rf_cv_scores.mean())\n",
        "\n",
        "\n",
        "gb_cv_scores = cross_val_score(gb_model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "print(\"Cross-Validation MSE for Gradient Boosting:\", -gb_cv_scores.mean())\n",
        "\n",
        "\n",
        "lr_cv_scores = cross_val_score(lr_model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "print(\"Cross-Validation MSE for Linear Regression:\", -lr_cv_scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q6hUFRJgtqa",
        "outputId": "c18310c6-0888-4ce2-abee-6efb7c0dc1c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation MSE for Random Forest: 0.0024993881710238955\n",
            "Cross-Validation MSE for Gradient Boosting: 0.001014481814555597\n",
            "Cross-Validation MSE for Linear Regression: 1.9524307404220043e-30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "noise_train = np.random.normal(0, 0.1, size=X_train_scaled.shape)\n",
        "noise_test = np.random.normal(0, 0.1, size=X_test_scaled.shape)\n",
        "\n",
        "\n",
        "print(f\"Forma de X_train_scaled: {X_train_scaled.shape}\")\n",
        "print(f\"Forma de ruido_train: {noise_train.shape}\")\n",
        "print(f\"Forma de X_test_scaled: {X_test_scaled.shape}\")\n",
        "print(f\"Forma de ruido_test: {noise_test.shape}\")\n",
        "\n",
        "\n",
        "X_train_noisy = X_train_scaled + noise_train\n",
        "X_test_noisy = X_test_scaled + noise_test\n",
        "\n",
        "\n",
        "rf_model.fit(X_train_noisy, y_train)\n",
        "y_pred_rf_noisy = rf_model.predict(X_test_noisy)\n",
        "\n",
        "\n",
        "print(\"MSE con ruido (Random Forest):\", mean_squared_error(y_test, y_pred_rf_noisy))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boBwzonGg0Hl",
        "outputId": "55eb55ce-0122-400c-9a09-6455a7d40a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de X_train_scaled: (321, 5)\n",
            "Forma de ruido_train: (321, 5)\n",
            "Forma de X_test_scaled: (81, 5)\n",
            "Forma de ruido_test: (81, 5)\n",
            "MSE con ruido (Random Forest): 0.011029465142508106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "ridge_model.fit(X_train_scaled, y_train)\n",
        "y_pred_ridge = ridge_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "print(\"Mean Squared Error (Ridge):\", mean_squared_error(y_test, y_pred_ridge))\n",
        "print(\"R2 Score (Ridge):\", r2_score(y_test, y_pred_ridge))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln8Sb7Czg5ht",
        "outputId": "d861adff-b01f-4a59-ac19-18995d6d8396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (Ridge): 6.302397374746012e-05\n",
            "R2 Score (Ridge): 0.9999359068451033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf_model = RandomForestRegressor(n_estimators=50, max_depth=6, min_samples_split=10, random_state=42)\n",
        "rf_model.fit(X_train_noisy, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_noisy)\n",
        "print(\"MSE con Random Forest:\", mean_squared_error(y_test, y_pred_rf))\n",
        "print(\"R2 con Random Forest:\", r2_score(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xADHskNXimqv",
        "outputId": "66f54e63-9aaf-4044-cb57-1693309508b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE con Random Forest: 0.010267312139663127\n",
            "R2 con Random Forest: 0.9895585062602187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)\n",
        "gb_model.fit(X_train_noisy, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test_noisy)\n",
        "print(\"MSE con Gradient Boosting:\", mean_squared_error(y_test, y_pred_gb))\n",
        "print(\"R2 con Gradient Boosting:\", r2_score(y_test, y_pred_gb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnNNsZIUiuDx",
        "outputId": "f9b79a6e-015c-43ab-dd27-e1da7e62387a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE con Gradient Boosting: 0.014348278856871762\n",
            "R2 con Gradient Boosting: 0.9854083072743147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "ridge_model.fit(X_train_noisy, y_train)\n",
        "y_pred_ridge = ridge_model.predict(X_test_noisy)\n",
        "\n",
        "\n",
        "print(\"MSE con Ridge:\", mean_squared_error(y_test, y_pred_ridge))\n",
        "print(\"R2 con Ridge:\", r2_score(y_test, y_pred_ridge))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVK51GjgiyOS",
        "outputId": "6a441199-e323-4b09-d129-c9c3f62bf5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE con Ridge: 0.007060000020380404\n",
            "R2 con Ridge: 0.9928202293830256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "rf_cv_scores = cross_val_score(rf_model, X_train_noisy, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "print(\"Cross-Validation MSE for Random Forest:\", -rf_cv_scores.mean())\n",
        "\n",
        "\n",
        "gb_cv_scores = cross_val_score(gb_model, X_train_noisy, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "print(\"Cross-Validation MSE for Gradient Boosting:\", -gb_cv_scores.mean())\n",
        "\n",
        "\n",
        "ridge_cv_scores = cross_val_score(ridge_model, X_train_noisy, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "print(\"Cross-Validation MSE for Ridge Regression:\", -ridge_cv_scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SQdMh7Vi7XV",
        "outputId": "fa25264e-18a1-4a50-bdc7-56690060e6c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation MSE for Random Forest: 0.010297295897152548\n",
            "Cross-Validation MSE for Gradient Boosting: 0.009904848223311979\n",
            "Cross-Validation MSE for Ridge Regression: 0.006628291691205819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "noise_train = np.random.normal(0, 0.5, size=X_train_scaled.shape)\n",
        "noise_test = np.random.normal(0, 0.5, size=X_test_scaled.shape)\n",
        "\n",
        "\n",
        "X_train_noisy = X_train_scaled + noise_train\n",
        "X_test_noisy = X_test_scaled + noise_test\n"
      ],
      "metadata": {
        "id": "hso8pANfjAT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "X_train_sub, X_valid_sub, y_train_sub, y_valid_sub = train_test_split(X_train_noisy, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "gb_model = GradientBoostingRegressor(n_estimators=1000, max_depth=6, learning_rate=0.1, random_state=42)\n",
        "\n",
        "\n",
        "gb_model.fit(X_train_sub, y_train_sub)\n",
        "\n",
        "\n",
        "y_pred_gb = gb_model.predict(X_valid_sub)\n",
        "\n",
        "\n",
        "print(\"MSE con Gradient Boosting (sin Early Stopping):\", mean_squared_error(y_valid_sub, y_pred_gb))\n",
        "print(\"R2 con Gradient Boosting (sin Early Stopping):\", r2_score(y_valid_sub, y_pred_gb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SH23LgtjC-0",
        "outputId": "8cf6734b-d62c-4691-9160-d5fd9453a920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE con Gradient Boosting (sin Early Stopping): 0.1278595202073551\n",
            "R2 con Gradient Boosting (sin Early Stopping): 0.8010471383735622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "y_pred_train = gb_model.predict(X_train_noisy)\n",
        "\n",
        "\n",
        "r2_train = r2_score(y_train, y_pred_train)\n",
        "print(f\"R² en entrenamiento: {r2_train}\")\n",
        "\n",
        "\n",
        "y_pred_test = gb_model.predict(X_test_noisy)\n",
        "\n",
        "\n",
        "r2_test = r2_score(y_test, y_pred_test)\n",
        "print(f\"R² en prueba: {r2_test}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1XyFf-Clxfw",
        "outputId": "daa909bd-71ed-4bec-caf2-ef94e22b2ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² en entrenamiento: 0.9627248659648793\n",
            "R² en prueba: 0.8501829672886044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb_model = GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42\n",
        ")\n",
        "gb_model.fit(X_train_noisy, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test_noisy)\n",
        "\n",
        "print(f\"R² en entrenamiento: {r2_score(y_train, gb_model.predict(X_train_noisy))}\")\n",
        "print(f\"R² en prueba: {r2_score(y_test, y_pred_gb)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFmDGzLAmxmr",
        "outputId": "331bbe43-2954-4201-ceea-b875c71f9c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² en entrenamiento: 0.9891774754011492\n",
            "R² en prueba: 0.8581955519955642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    min_samples_split=10,\n",
        "    random_state=42\n",
        ")\n",
        "rf_model.fit(X_train_noisy, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_noisy)\n",
        "\n",
        "print(f\"R² en entrenamiento: {r2_score(y_train, rf_model.predict(X_train_noisy))}\")\n",
        "print(f\"R² en prueba: {r2_score(y_test, y_pred_rf)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIal0WdEm0N8",
        "outputId": "5cd8d47e-9329-4d87-aa34-04fb85f1d8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² en entrenamiento: 0.9251256493167446\n",
            "R² en prueba: 0.8471174663416859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "ridge_model.fit(X_train_noisy, y_train)\n",
        "y_pred_ridge = ridge_model.predict(X_test_noisy)\n",
        "\n",
        "print(f\"R² en entrenamiento: {r2_score(y_train, ridge_model.predict(X_train_noisy))}\")\n",
        "print(f\"R² en prueba: {r2_score(y_test, y_pred_ridge)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dM8tgZqm37j",
        "outputId": "fdf3203e-ab92-486f-b19a-52ba44b62363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² en entrenamiento: 0.8849696979645438\n",
            "R² en prueba: 0.8718785318785442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb_model = GradientBoostingRegressor(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.01,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "gb_model.fit(X_train_noisy, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test_noisy)\n",
        "\n",
        "print(f\"R² en entrenamiento: {r2_score(y_train, gb_model.predict(X_train_noisy))}\")\n",
        "print(f\"R² en prueba: {r2_score(y_test, y_pred_gb)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0t76EGfnAqS",
        "outputId": "a6089fa2-1503-4d86-e688-219c19f82314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² en entrenamiento: 0.9447559473662018\n",
            "R² en prueba: 0.8197712370436584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "rf_cv_scores = cross_val_score(rf_model, X_train_noisy, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "print(f\"Cross-Validation MSE for Random Forest: {-rf_cv_scores.mean()}\")\n",
        "\n",
        "\n",
        "gb_cv_scores = cross_val_score(gb_model, X_train_noisy, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "print(f\"Cross-Validation MSE for Gradient Boosting: {-gb_cv_scores.mean()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-902gsInD_z",
        "outputId": "36deea66-c2b1-4889-8b74-b668b77598e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation MSE for Random Forest: 0.11147644415345961\n",
            "Cross-Validation MSE for Gradient Boosting: 0.1263775978237321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "\n",
        "\n",
        "ridge_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = ridge_model.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "print(f\"R² en entrenamiento: {r2_score(y_train, ridge_model.predict(X_train))}\")\n",
        "print(f\"R² en prueba: {r2_score(y_test, y_pred)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQZSuynqoUKK",
        "outputId": "56824c51-bd9e-4bfa-8343-f140080175f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² en entrenamiento: 0.9998873167838311\n",
            "R² en prueba: 0.9998805855233401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=6.38661e-22): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
          ]
        }
      ]
    }
  ]
}